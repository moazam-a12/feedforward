{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a508996d-fb95-4061-aed8-5e28fd2fcc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT model and tokenizer loaded successfully.\n",
      "Feedback data loaded successfully from column 'Feedback'.\n",
      "Feedback texts preprocessed successfully.\n",
      "Model and inputs moved to mps.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Load and Prepare Models and Data\n",
    "# Specify paths to trained_models folder and feedback data\n",
    "trained_models_dir = '/Users/moazam_a12/Sentiment Analysis of Internship Feedback/trained models'\n",
    "feedback_data_path = '/Users/moazam_a12/Sentiment Analysis of Internship Feedback/data/synthetic_intern_feedback.csv'\n",
    "\n",
    "import os\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "bert_model_path = os.path.join(trained_models_dir, 'bert_model')\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(bert_model_path):\n",
    "        raise FileNotFoundError(f\"BERT model directory {bert_model_path} does not exist.\")\n",
    "    required_files = ['config.json', 'model.safetensors', 'tokenizer_config.json']\n",
    "    missing_files = [f for f in required_files if not os.path.exists(os.path.join(bert_model_path, f))]\n",
    "    if missing_files:\n",
    "        raise FileNotFoundError(f\"Missing files in {bert_model_path}: {missing_files}\")\n",
    "    bert_model = DistilBertForSequenceClassification.from_pretrained(bert_model_path)\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(bert_model_path)\n",
    "    print(\"DistilBERT model and tokenizer loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading DistilBERT model from {bert_model_path}: {e}\")\n",
    "    print(\"Ensure 'bert_model' directory contains 'config.json', 'model.safetensors', and tokenizer files.\")\n",
    "    # Fallback to a sample text with a freshly loaded tokenizer\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    feedback_texts = ['Sample feedback for testing.']\n",
    "    df = pd.DataFrame({'Feedback': feedback_texts})\n",
    "else:\n",
    "    try:\n",
    "        df = pd.read_csv(feedback_data_path)\n",
    "        possible_columns = ['feedback', 'Feedback', 'text', 'Text', 'comment', 'Comment']\n",
    "        feedback_column = None\n",
    "        for col in possible_columns:\n",
    "            if col in df.columns:\n",
    "                feedback_column = col\n",
    "                break\n",
    "        if feedback_column is None:\n",
    "            raise ValueError(\"No feedback column found. Available columns: \" + str(df.columns.tolist()))\n",
    "        feedback_texts = df[feedback_column].tolist()\n",
    "        print(f\"Feedback data loaded successfully from column '{feedback_column}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data from {feedback_data_path}: {e}\")\n",
    "        feedback_texts = ['Sample feedback for testing.']\n",
    "        df = pd.DataFrame({'Feedback': feedback_texts})\n",
    "\n",
    "def preprocess_bert(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "\n",
    "try:\n",
    "    bert_inputs = preprocess_bert(feedback_texts)\n",
    "    print(\"Feedback texts preprocessed successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error preprocessing texts: {e}\")\n",
    "    bert_inputs = preprocess_bert(['Sample feedback for testing.'])\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "bert_model.to(device)\n",
    "bert_inputs = {k: v.to(device) for k, v in bert_inputs.items()}\n",
    "print(f\"Model and inputs moved to {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970222e1-3473-4c76-a9cf-9dcb29a9b915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying: 100%|██████████████████████████| 1563/1563 [14:10<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Trends:\n",
      "Neutral: 34.0%\n",
      "Positive: 33.0%\n",
      "Negative: 33.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Classify Feedback and Show Sentiment Trends\n",
    "from tqdm import tqdm\n",
    "\n",
    "def classify_batch(inputs, batch_size=64):\n",
    "    try:\n",
    "        predictions = []\n",
    "        total_batches = (len(inputs['input_ids']) + batch_size - 1) // batch_size\n",
    "        for i in tqdm(range(0, len(inputs['input_ids']), batch_size), total=total_batches, desc=\"Classifying\"):\n",
    "            batch_inputs = {k: v[i:i+batch_size] for k, v in inputs.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = bert_model(**batch_inputs)\n",
    "            batch_predictions = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "            predictions.extend(batch_predictions)\n",
    "        return [{0: 'Negative', 1: 'Neutral', 2: 'Positive'}[p] for p in predictions]\n",
    "    except Exception as e:\n",
    "        print(f\"Error during classification: {e}\")\n",
    "        return ['Neutral'] * len(inputs['input_ids'])\n",
    "\n",
    "df['predicted_sentiment'] = classify_batch(bert_inputs)\n",
    "\n",
    "sentiment_dist = df['predicted_sentiment'].value_counts(normalize=True) * 100\n",
    "print(\"Sentiment Trends:\")\n",
    "for sentiment, percentage in sentiment_dist.items():\n",
    "    print(f\"{sentiment}: {percentage:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa0a4ded-f54a-420c-8095-0bdc8a40ef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative reviews: 33000\n",
      "\n",
      "10 Randomly Selected Negative Feedback Entries:\n",
      "Review 1: My role was ill-defined, leading to constant confusion and frustration. I learned to manage my time effectively under pressure. I appreciated the free...\n",
      "Review 2: The onboarding process was poorly structured and left me confused for weeks. At least the networking opportunities were abundant. I appreciated the fr...\n",
      "Review 3: The onboarding process was poorly structured and left me confused for weeks. The office environment was vibrant and welcoming. At least the networking...\n",
      "Review 4: There was a general lack of guidance, and feedback was either delayed or missing. Remote work made collaboration tricky at times. At least the network...\n",
      "Review 5: There was a general lack of guidance, and feedback was either delayed or missing. I appreciated the freedom to explore new ideas, although guidance wa...\n",
      "Review 6: I faced technical challenges that were ignored by my supervisors. I learned to manage my time effectively under pressure. The office environment was v...\n",
      "Review 7: There was a general lack of guidance, and feedback was either delayed or missing. I learned to manage my time effectively under pressure. The office e...\n",
      "Review 8: My role was ill-defined, leading to constant confusion and frustration. I learned to manage my time effectively under pressure. Remote work made colla...\n",
      "Review 9: Team dynamics were often toxic, making it difficult to engage openly. At least the networking opportunities were abundant. The office environment was ...\n",
      "Review 10: I was often assigned mundane tasks that didn’t contribute to my learning. I appreciated the freedom to explore new ideas, although guidance was sporad...\n",
      "\n",
      "Insufficient Aspects in All Negative Feedback:\n",
      "Learning (TF-IDF score: 1943.17)\n",
      "Experience (TF-IDF score: 1838.15)\n",
      "Work (TF-IDF score: 1796.76)\n",
      "Opportunities (TF-IDF score: 1353.38)\n",
      "Structured (TF-IDF score: 1324.79)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "def extract_negative_themes(df, feedback_column, num_reviews=10, use_all_feedback=False):\n",
    "    negative_feedback = df[df['predicted_sentiment'] == 'Negative'][feedback_column]\n",
    "    num_negative_reviews = len(negative_feedback)\n",
    "    print(f\"Number of negative reviews: {num_negative_reviews}\")\n",
    "\n",
    "    if num_negative_reviews == 0:\n",
    "        print(\"No negative feedback found. Cannot extract themes.\")\n",
    "        return [('no themes found', 0)]\n",
    "\n",
    "    random_indices = np.random.choice(negative_feedback.index, size=num_reviews, replace=False)\n",
    "    selected_feedback = negative_feedback.loc[random_indices].tolist()\n",
    "    \n",
    "    print(f\"\\n{num_reviews} Randomly Selected Negative Feedback Entries:\")\n",
    "    for i, text in enumerate(selected_feedback, 1):\n",
    "        print(f\"Review {i}: {text[:150]}...\" if len(text) > 150 else f\"Review {i}: {text}\")\n",
    "\n",
    "    try:\n",
    "        from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "        custom_stop_words = list(ENGLISH_STOP_WORDS) + [\n",
    "            'intern', 'internship', 'was', 'were', 'felt', 'like', 'it', 'and',\n",
    "            'there', 'any', 'despite', 'hardly', 'left', 'rather', 'than', 'job',\n",
    "            'sometimes', 'least', 'english'\n",
    "        ]\n",
    "\n",
    "        feedback_to_analyze = negative_feedback if use_all_feedback else selected_feedback\n",
    "        vectorizer_themes = TfidfVectorizer(\n",
    "            stop_words=custom_stop_words,\n",
    "            ngram_range=(1, 3),\n",
    "            min_df=1 if not use_all_feedback else 10,\n",
    "            max_df=0.8\n",
    "        )\n",
    "        X = vectorizer_themes.fit_transform(feedback_to_analyze)\n",
    "        feature_names = vectorizer_themes.get_feature_names_out()\n",
    "        tfidf_scores = X.sum(axis=0).A1\n",
    "        word_score_dict = dict(zip(feature_names, tfidf_scores))\n",
    "        top_themes = Counter(word_score_dict).most_common(5)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting themes: {e}\")\n",
    "        top_themes = [('no themes found', 1)]\n",
    "\n",
    "    scope = \"All Negative Feedback\" if use_all_feedback else f\"Selected {num_reviews} Negative Feedback\"\n",
    "    print(f\"\\nInsufficient Aspects in {scope}:\")\n",
    "    for theme, score in top_themes:\n",
    "        formatted_theme = ' '.join(word.capitalize() for word in theme.split())\n",
    "        print(f\"{formatted_theme} (TF-IDF score: {score:.2f})\")\n",
    "\n",
    "    return top_themes\n",
    "\n",
    "# Change num_reviews to adjust the number of displayed reviews\n",
    "# Set use_all_feedback=True for themes from all negative feedback, False for selected reviews\n",
    "top_themes = extract_negative_themes(df, feedback_column, num_reviews=10, use_all_feedback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a809f8-6d1e-42ed-a867-705e7816c9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
