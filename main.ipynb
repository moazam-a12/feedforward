{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d644acf-8801-4c2e-a3f3-9502eb436a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required packages are already installed.\n",
      "NLTK resource 'punkt_tab' already exists at /Users/moazam_a12/Sentiment Analysis of Internship Feedback/nltk_data/tokenizers/punkt_tab.\n",
      "Contents of /Users/moazam_a12/Sentiment Analysis of Internship Feedback/nltk_data/tokenizers/punkt_tab: ['dutch', 'czech', 'malayalam', 'german', 'estonian', 'slovene', 'turkish', 'russian', 'README', 'italian', 'english', 'greek', 'norwegian', 'portuguese', 'finnish', 'danish', 'polish', 'french', 'swedish', 'spanish']\n",
      "NLTK resource 'stopwords' already exists at /Users/moazam_a12/Sentiment Analysis of Internship Feedback/nltk_data/corpora/stopwords.\n",
      "Contents of /Users/moazam_a12/Sentiment Analysis of Internship Feedback/nltk_data/corpora/stopwords: ['albanian', 'dutch', 'catalan', 'german', 'slovene', 'hinglish', 'hungarian', 'romanian', 'kazakh', 'turkish', 'russian', 'README', 'italian', 'english', 'greek', 'tajik', 'norwegian', 'portuguese', 'hebrew', 'finnish', 'danish', 'french', 'swedish', 'belarusian', 'azerbaijani', 'spanish', 'tamil', 'chinese', 'indonesian', 'arabic', 'nepali', 'bengali', 'basque']\n",
      "NLTK resource 'wordnet' already exists at /Users/moazam_a12/Sentiment Analysis of Internship Feedback/nltk_data/corpora/wordnet.\n",
      "Contents of /Users/moazam_a12/Sentiment Analysis of Internship Feedback/nltk_data/corpora/wordnet: ['lexnames', 'index.noun', 'LICENSE', 'verb.exc', 'data.adj', 'data.adv', 'cntlist.rev', 'adj.exc', 'data.noun', 'noun.exc', 'README', 'data.verb', 'adv.exc', 'citation.bib', 'index.adv', 'index.adj', 'index.verb', 'index.sense']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "project_root = \"/Users/moazam_a12/Sentiment Analysis of Internship Feedback\"\n",
    "sys.path.append(os.path.abspath(project_root))\n",
    "from utils.preprocess import load_and_clean_data, preprocess_for_logistic_regression, preprocess_for_transformers, install_requirements, download_nltk_resources\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "install_requirements()\n",
    "download_nltk_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51befa8c-eec5-403f-8295-57b38148eca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load file from: /Users/moazam_a12/Sentiment Analysis of Internship Feedback/data/synthetic_intern_feedback.csv\n",
      "Removed 0 duplicate entries. 100000 entries remain.\n",
      "Dataset loaded with 100000 entries after deduplication.\n",
      "TF-IDF preprocessed data saved to /Users/moazam_a12/Sentiment Analysis of Internship Feedback/utils/preprocessed_data_tfidf.pkl\n",
      "TF-IDF features shape: (100000, 780)\n",
      "Transformer preprocessed data saved to /Users/moazam_a12/Sentiment Analysis of Internship Feedback/utils/preprocessed_data_transformer.pt\n",
      "Transformer input_ids shape: torch.Size([100000, 128])\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "file_path = os.path.join(project_root, 'data/synthetic_intern_feedback.csv')\n",
    "print(f\"Attempting to load file from: {file_path}\")\n",
    "df = load_and_clean_data(file_path)\n",
    "print(f\"Dataset loaded with {len(df)} entries after deduplication.\")\n",
    "X_tfidf, y, tfidf = preprocess_for_logistic_regression(df)\n",
    "print(f\"TF-IDF features shape: {X_tfidf.shape}\")\n",
    "encodings, labels, tokenizer = preprocess_for_transformers(df, max_length=128)\n",
    "print(f\"Transformer input_ids shape: {encodings['input_ids'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7af4993-0654-4ac5-91a0-b0833d643c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "Logistic Regression model is training...\n",
      "Logistic Regression model is trained.\n",
      "Accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      1.00      1.00      6544\n",
      "     Neutral       1.00      1.00      1.00      6738\n",
      "    Positive       1.00      1.00      1.00      6718\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       1.00      1.00      1.00     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "5-fold CV Accuracy: 1.0000 (+/- 0.0000)\n",
      "BERT model is training...\n",
      "Encodings input_ids shape: torch.Size([100000, 128])\n",
      "Labels shape: (100000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 1:08:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model is trained.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 06:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT evaluation results: {'eval_loss': 1.1255614253968815e-06, 'eval_accuracy': 1.0, 'eval_runtime': 391.5128, 'eval_samples_per_second': 51.084, 'eval_steps_per_second': 12.771, 'epoch': 1.0}\n",
      "Model training completed.\n"
     ]
    }
   ],
   "source": [
    "from models.train_model import train_models\n",
    "print(\"Starting model training...\")\n",
    "train_models(project_root, verbose=True)\n",
    "print(\"Model training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1e1232-ee06-4c13-a224-5e84860db735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
